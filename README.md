# ğŸ± Kedi Cinsi Tahmin UygulamasÄ±

Derin Ã¶ÄŸrenme tabanlÄ± geliÅŸmiÅŸ kedi cinsi sÄ±nÄ±flandÄ±rma sistemi. 59 farklÄ± kedi cinsini yÃ¼ksek doÄŸrulukla tahmin eder.

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.5.1-red.svg)](https://pytorch.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ Ä°Ã§indekiler

- [Ã–zellikler](#Ã¶zellikler)
- [Model Mimarisi](#model-mimarisi)
- [Kurulum](#kurulum)
  - [Docker ile Kurulum (Ã–nerilen)](#docker-ile-kurulum-Ã¶nerilen)
  - [Manuel Kurulum](#manuel-kurulum)
- [KullanÄ±m](#kullanÄ±m)
- [Model EÄŸitimi](#model-eÄŸitimi)
- [Performans](#performans)
- [Veri Seti](#veri-seti)
- [Teknolojiler](#teknolojiler)
- [KatkÄ±da Bulunma](#katkÄ±da-bulunma)
- [Lisans](#lisans)

## âœ¨ Ã–zellikler

- ğŸ¯ **59 Kedi Cinsi DesteÄŸi**: Abyssinian'dan Tabby'ye kadar geniÅŸ cins yelpazesi
- ğŸ§  **Ensemble Model**: ResNet50 + EfficientNet-B0 + MobileNetV3 kombinasyonu
- âš¡ **Mixed Precision Training**: FP16 desteÄŸi ile hÄ±zlÄ± eÄŸitim
- ğŸ”„ **Gradient Accumulation**: DÃ¼ÅŸÃ¼k VRAM iÃ§in optimize edilmiÅŸ
- ğŸ›¡ï¸ **Anti-Overfitting**: Strong augmentation, label smoothing, early stopping
- ğŸ³ **Docker DesteÄŸi**: Kolay deployment ve reproducibility
- ğŸ“Š **DetaylÄ± Raporlama**: Training history, confusion matrix, performance metrics

## ğŸ—ï¸ Model Mimarisi

### Optimal Ensemble (Final Model)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Optimal 3-Model Ensemble           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  ResNet50    â”‚  â”‚ EfficientNet â”‚         â”‚
â”‚  â”‚  (24.6M)     â”‚  â”‚  -B0 (5.3M)  â”‚         â”‚
â”‚  â”‚  64.67%      â”‚  â”‚  60.66%      â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â”‚                 â”‚                  â”‚
â”‚         â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚         â”‚   â”‚   MobileNetV3-Large  â”‚         â”‚
â”‚         â”‚   â”‚      (5.4M)          â”‚         â”‚
â”‚         â”‚   â”‚      60.06%          â”‚         â”‚
â”‚         â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â”‚              â”‚                     â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                â”‚                             â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚         â”‚  Meta-Learner   â”‚                  â”‚
â”‚         â”‚  (FC Layers)    â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                â”‚                             â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚         â”‚ Final Predictionâ”‚                  â”‚
â”‚         â”‚    63.85%       â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Teknik Ã–zellikler
- **Total Parameters**: ~35.3M
- **Mixed Precision**: FP16 (VRAM %50 azaltma)
- **Batch Size**: 8 (Virtual: 32 with gradient accumulation)
- **Image Size**: 224x224
- **Augmentation**: RandomCrop, ColorJitter, Rotation, Erasing
- **Regularization**: Dropout, Label Smoothing, Weight Decay

## ğŸš€ Kurulum

### Docker ile Kurulum (Ã–nerilen)

#### Gereksinimler
- Docker Desktop (Windows/Mac) veya Docker Engine (Linux)
- NVIDIA GPU (opsiyonel, CPU'da da Ã§alÄ±ÅŸÄ±r)
- NVIDIA Container Toolkit (GPU kullanÄ±mÄ± iÃ§in)

#### 1. Repoyu KlonlayÄ±n
```bash
git clone https://github.com/berkegazioglu/kedi-cins-tahmini.git
cd kedi-cins-tahmini
```

#### 2. Docker Image Build Edin
```bash
# CPU versiyonu
docker-compose build

# GPU versiyonu (NVIDIA GPU gerekli)
docker-compose -f docker-compose.yml build
```

#### 3. UygulamayÄ± BaÅŸlatÄ±n
```bash
# Web uygulamasÄ±nÄ± baÅŸlat
docker-compose up

# Arka planda Ã§alÄ±ÅŸtÄ±r
docker-compose up -d
```

#### 4. TarayÄ±cÄ±da AÃ§Ä±n
```
http://localhost:8501
```

#### 5. Durdurma
```bash
docker-compose down
```

### Manuel Kurulum

#### Gereksinimler
- Python 3.11+
- CUDA 12.1+ (GPU iÃ§in)
- 4GB+ RAM (CPU) veya 4GB+ VRAM (GPU)

#### 1. Repoyu KlonlayÄ±n
```bash
git clone https://github.com/berkegazioglu/kedi-cins-tahmini.git
cd kedi-cins-tahmini
```

#### 2. Virtual Environment OluÅŸturun
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

#### 3. Gereksinimleri YÃ¼kleyin
```bash
# GPU versiyonu (NVIDIA CUDA gerekli)
pip install -r requirements.txt

# CPU versiyonu
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
pip install -r requirements.txt
```

#### 4. Model DosyalarÄ±nÄ± Ä°ndirin
```bash
# Pre-trained modeller (opsiyonel)
# Modeller otomatik olarak ilk Ã§alÄ±ÅŸtÄ±rmada indirilecektir
# Manuel indirmek iÃ§in:
python download_models.py
```

#### 5. UygulamayÄ± BaÅŸlatÄ±n
```bash
# Streamlit web uygulamasÄ±
streamlit run app_optimal_ensemble.py

# Flask API (alternatif)
python app_resnet50.py
```

## ğŸ’» KullanÄ±m

### Web ArayÃ¼zÃ¼ ile KullanÄ±m

1. UygulamayÄ± baÅŸlatÄ±n (Docker veya manuel)
2. TarayÄ±cÄ±da aÃ§Ä±n: `http://localhost:8501`
3. "Browse files" ile kedi fotoÄŸrafÄ± yÃ¼kleyin
4. "Tahmin Et" butonuna tÄ±klayÄ±n
5. SonuÃ§larÄ± gÃ¶rÃ¼n:
   - En olasÄ± 5 cins
   - GÃ¼ven yÃ¼zdeleri
   - Her modelin tahmini
   - Ensemble karÅŸÄ±laÅŸtÄ±rmasÄ±

### Python API ile KullanÄ±m

```python
from PIL import Image
import torch
from torchvision import transforms

# Model yÃ¼kleme
from train_optimal_ensemble import OptimalEnsemble

model = OptimalEnsemble(num_classes=59)
model.load_state_dict(torch.load('runs/optimal_ensemble/optimal_ensemble_final.pth'))
model.eval()

# GÃ¶rÃ¼ntÃ¼ hazÄ±rlama
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

image = Image.open('cat_image.jpg').convert('RGB')
input_tensor = transform(image).unsqueeze(0)

# Tahmin
with torch.no_grad():
    output = model(input_tensor, use_meta=True)
    probabilities = torch.softmax(output, dim=1)
    top5_prob, top5_idx = torch.topk(probabilities, 5)

print(f"Top 5 Tahminler:")
for prob, idx in zip(top5_prob[0], top5_idx[0]):
    print(f"  {class_names[idx]}: {prob*100:.2f}%")
```

### Komut SatÄ±rÄ± ile KullanÄ±m

```bash
# Tekil tahmin
python predict_optimal_ensemble.py --image path/to/cat.jpg

# Batch tahmin
python predict_optimal_ensemble.py --folder path/to/cat_images/

# DetaylÄ± analiz
python predict_optimal_ensemble.py --image cat.jpg --detailed
```

## ğŸ“ Model EÄŸitimi

### HÄ±zlÄ± BaÅŸlangÄ±Ã§

```bash
# Optimal ensemble eÄŸitimi (Ã¶nerilen)
python train_optimal_ensemble.py

# Tek model eÄŸitimi
python train_resnet50.py
```

### EÄŸitim Parametreleri

```python
# train_optimal_ensemble.py iÃ§inde ayarlar
BATCH_SIZE = 8              # GerÃ§ek batch size
ACCUMULATION_STEPS = 4      # Sanal batch = 32
EPOCHS_BASE = 15            # Base model epoch'larÄ±
EPOCHS_META = 10            # Meta-learner epoch'larÄ±
EPOCHS_FINE = 5             # Fine-tuning epoch'larÄ±
```

### Ã–zel EÄŸitim

```bash
# Custom parameters
python train_optimal_ensemble.py \
    --batch-size 16 \
    --epochs-base 20 \
    --epochs-meta 12 \
    --epochs-fine 8 \
    --lr 0.001
```

### EÄŸitim Ä°zleme

```bash
# Training history gÃ¶rselleÅŸtirme
python visualize_training.py

# TensorBoard (opsiyonel)
tensorboard --logdir runs/optimal_ensemble
```

## ğŸ“Š Performans

### Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Model | Parameters | Accuracy | Training Time | VRAM Usage |
|-------|------------|----------|---------------|------------|
| ResNet50 | 24.6M | 64.67% | ~4 hours | 3.2 GB |
| EfficientNet-B0 | 5.3M | 60.66% | ~4.5 hours | 2.8 GB |
| MobileNetV3 | 5.4M | 60.06% | ~2.5 hours | 2.5 GB |
| **Optimal Ensemble** | **35.3M** | **63.85%** | **~16 hours** | **3.8 GB** |

### Cins BazlÄ± Performance (Top 10)

| Kedi Cinsi | Precision | Recall | F1-Score |
|------------|-----------|--------|----------|
| British Shorthair | 78.3% | 82.1% | 80.1% |
| Persian | 76.5% | 79.8% | 78.1% |
| Siamese | 74.2% | 77.3% | 75.7% |
| Maine Coon | 72.8% | 75.6% | 74.2% |
| Bengal | 71.3% | 73.9% | 72.6% |
| Russian Blue | 69.7% | 72.4% | 71.0% |
| Ragdoll | 68.4% | 71.2% | 69.8% |
| Sphynx | 67.2% | 69.8% | 68.5% |
| Abyssinian | 65.9% | 68.5% | 67.2% |
| Scottish Fold | 64.7% | 67.1% | 65.9% |

### Hardware Gereksinimleri

**Minimum (CPU):**
- CPU: Intel i5 / AMD Ryzen 5
- RAM: 8 GB
- Disk: 10 GB
- Inference: ~2-3 saniye/gÃ¶rÃ¼ntÃ¼

**Ã–nerilen (GPU):**
- GPU: NVIDIA RTX 3050 (4GB) veya Ã¼stÃ¼
- RAM: 16 GB
- VRAM: 4 GB
- Disk: 20 GB
- Inference: ~0.1 saniye/gÃ¶rÃ¼ntÃ¼

## ğŸ“ Veri Seti

### YapÄ±
```
images_split/
â”œâ”€â”€ train/              # 88,741 gÃ¶rÃ¼ntÃ¼
â”‚   â”œâ”€â”€ Abyssinian/
â”‚   â”œâ”€â”€ American Bobtail/
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ Tabby/
â””â”€â”€ val/                # 21,816 gÃ¶rÃ¼ntÃ¼
    â”œâ”€â”€ Abyssinian/
    â”œâ”€â”€ American Bobtail/
    â”œâ”€â”€ ...
    â””â”€â”€ Tabby/
```

### Desteklenen Kedi Cinsleri (59)

<details>
<summary>TÃ¼m cinsleri gÃ¶ster</summary>

1. Abyssinian
2. American Bobtail
3. American Curl
4. American Shorthair
5. American Wirehair
6. Applehead Siamese
7. Balinese
8. Bengal
9. Birman
10. Bombay
11. British Shorthair
12. Burmese
13. Burmilla
14. Calico
15. Canadian Hairless (Sphynx)
16. Chartreux
17. Chausie
18. Chinchilla
19. Cornish Rex
20. Cymric
21. Devon Rex
22. Dilute Calico
23. Dilute Tortoiseshell
24. Domestic Long Hair
25. Domestic Medium Hair
26. Domestic Short Hair
27. Egyptian Mau
28. Exotic Shorthair
29. Extra-Toes Cat (Polydactyl)
30. Havana
31. Himalayan
32. Japanese Bobtail
33. Javanese
34. Korat
35. LaPerm
36. Maine Coon
37. Manx
38. Munchkin
39. Nebelung
40. Norwegian Forest Cat
41. Ocicat
42. Oriental Long Hair
43. Oriental Short Hair
44. Oriental Tabby
45. Persian
46. Pixiebob
47. Ragamuffin
48. Ragdoll
49. Russian Blue
50. Scottish Fold
51. Selkirk Rex
52. Siamese
53. Siberian
54. Silver
55. Singapura
56. Snowshoe
57. Somali
58. Sphynx
59. Tabby

</details>

### Veri ArtÄ±rma (Augmentation)

```python
# Training augmentations
- RandomResizedCrop(224, scale=(0.7, 1.0))
- RandomHorizontalFlip(p=0.5)
- RandomRotation(20Â°)
- ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1)
- RandomAffine(translate=(0.1, 0.1))
- RandomErasing(p=0.3, scale=(0.02, 0.15))
```

## ğŸ› ï¸ Teknolojiler

### Core
- **Python 3.11**: Ana programlama dili
- **PyTorch 2.5.1**: Deep learning framework
- **CUDA 12.1**: GPU acceleration

### Deep Learning
- **torchvision**: Pretrained models ve transforms
- **timm**: Advanced model architectures
- **torch.cuda.amp**: Mixed precision training

### Web & API
- **Streamlit**: Web UI
- **Flask**: REST API
- **Pillow**: Image processing

### Data & Visualization
- **NumPy**: Numerical computing
- **Pandas**: Data manipulation
- **Matplotlib/Seaborn**: Visualization
- **tqdm**: Progress bars

### DevOps
- **Docker**: Containerization
- **docker-compose**: Multi-container orchestration

## ğŸ“‚ Proje YapÄ±sÄ±

```
kedi-cins-tahmini/
â”œâ”€â”€ README.md                          # Bu dosya
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ Dockerfile                         # Docker image tanÄ±mÄ±
â”œâ”€â”€ docker-compose.yml                 # Docker compose yapÄ±landÄ±rmasÄ±
â”œâ”€â”€ deploy.sh                          # Linux deployment script
â”œâ”€â”€ deploy.ps1                         # Windows deployment script
â”œâ”€â”€ github-push.ps1                    # GitHub push script
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ cats.csv                       # Metadata
â”‚
â”œâ”€â”€ images_split/
â”‚   â”œâ”€â”€ train/                         # Training images
â”‚   â””â”€â”€ val/                           # Validation images
â”‚
â”œâ”€â”€ runs/
â”‚   â”œâ”€â”€ resnet50_v2/                   # ResNet50 model
â”‚   â”‚   â””â”€â”€ weights/
â”‚   â”‚       â””â”€â”€ best.pth
â”‚   â”œâ”€â”€ optimal_ensemble/              # Final ensemble
â”‚   â”‚   â”œâ”€â”€ optimal_ensemble_final.pth
â”‚   â”‚   â”œâ”€â”€ training_history.json
â”‚   â”‚   â””â”€â”€ class_names.json
â”‚   â””â”€â”€ super_ensemble/                # Experimental models
â”‚
â”œâ”€â”€ uploads/                           # User uploaded images
â”‚
â”œâ”€â”€ __pycache__/                       # Python cache
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ ensemble_model.py              # ResNet50, ConvNeXt models
â”‚   â”œâ”€â”€ transformer_models.py          # ViT, EfficientNetV2 models
â”‚   â””â”€â”€ augmentation_utils.py          # Training utilities
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_optimal_ensemble.py      # Final optimal ensemble trainer
â”‚   â”œâ”€â”€ train_resnet50.py              # Single ResNet50 trainer
â”‚   â”œâ”€â”€ train_resnet50_v2.py           # ResNet50 v2 trainer
â”‚   â”œâ”€â”€ train_ensemble.py              # 3-model ensemble trainer
â”‚   â”œâ”€â”€ train_super_ensemble.py        # 4-model super ensemble
â”‚   â”œâ”€â”€ train_fast_ensemble.py         # Fast ensemble variant
â”‚   â””â”€â”€ train_ensemble_2models.py      # 2-model baseline
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ evaluate_optimal_ensemble.py   # Ensemble evaluation
â”‚   â”œâ”€â”€ evaluate_resnet50.py           # ResNet50 evaluation
â”‚   â”œâ”€â”€ quick_evaluate.py              # Quick test
â”‚   â””â”€â”€ sample_evaluate.py             # Sample testing
â”‚
â”œâ”€â”€ prediction/
â”‚   â”œâ”€â”€ predict_optimal_ensemble.py    # Ensemble prediction
â”‚   â”œâ”€â”€ predict_resnet50.py            # ResNet50 prediction
â”‚   â””â”€â”€ predict_ensemble.py            # Basic ensemble prediction
â”‚
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ app_optimal_ensemble.py        # Optimal ensemble web app
â”‚   â”œâ”€â”€ app_resnet50.py                # ResNet50 web app
â”‚   â””â”€â”€ app_ensemble.py                # Basic ensemble web app
â”‚
â”œâ”€â”€ visualization/
â”‚   â”œâ”€â”€ visualize_training.py          # Training curves
â”‚   â””â”€â”€ visualize_ensemble_training.py # Ensemble analysis
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ check_model.py                 # Model checker
â”‚   â”œâ”€â”€ show_classes.py                # Class list viewer
â”‚   â””â”€â”€ test_ensemble.py               # Unit tests
â”‚
â””â”€â”€ experiments/
    â”œâ”€â”€ test_super_ensemble.py         # Super ensemble tests
    â””â”€â”€ test_optimal_ensemble.py       # Optimal ensemble tests
```

## ğŸ³ Docker DetaylarÄ±

### Dockerfile AÃ§Ä±klamasÄ±

```dockerfile
# Base image: Python 3.11 with CUDA support
FROM pytorch/pytorch:2.5.1-cuda12.1-cudnn9-runtime

# Install system dependencies
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements and install Python packages
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application files
COPY . .

# Expose Streamlit port
EXPOSE 8501

# Health check
HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health

# Run application
CMD ["streamlit", "run", "app_optimal_ensemble.py", "--server.address=0.0.0.0"]
```

### Docker Compose YapÄ±landÄ±rmasÄ±

```yaml
version: '3.8'

services:
  cat-classifier:
    build: .
    ports:
      - "8501:8501"
    volumes:
      - ./runs:/app/runs
      - ./uploads:/app/uploads
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

### Docker KomutlarÄ±

```bash
# Build
docker build -t cat-classifier .

# Run (CPU)
docker run -p 8501:8501 cat-classifier

# Run (GPU)
docker run --gpus all -p 8501:8501 cat-classifier

# Interactive shell
docker run -it cat-classifier /bin/bash

# View logs
docker logs -f <container-id>

# Stop
docker stop <container-id>

# Remove
docker rm <container-id>
docker rmi cat-classifier
```

## ğŸ”§ YapÄ±landÄ±rma

### EÄŸitim Parametreleri

`train_optimal_ensemble.py` dosyasÄ±nda:

```python
# Hardware Configuration
BATCH_SIZE = 8                    # GerÃ§ek batch size
ACCUMULATION_STEPS = 4            # Gradient accumulation
NUM_WORKERS = 4                   # DataLoader workers

# Training Epochs
EPOCHS_BASE = 15                  # Base model epochs
EPOCHS_META = 10                  # Meta-learner epochs
EPOCHS_FINE = 5                   # Fine-tuning epochs

# Optimization
LEARNING_RATE = 0.001             # Initial learning rate
WEIGHT_DECAY = 0.01               # L2 regularization
DROPOUT = 0.5                     # Dropout rate

# Regularization
LABEL_SMOOTHING = 0.1             # Label smoothing
EARLY_STOPPING_PATIENCE = 7       # Early stopping patience
GRADIENT_CLIP = 1.0               # Gradient clipping
```

### Model SeÃ§imi

```python
# Config: model_config.py (oluÅŸturulabilir)
MODEL_TYPE = "optimal_ensemble"   # veya "resnet50", "ensemble"
USE_MIXED_PRECISION = True        # FP16 training
USE_GRADIENT_ACCUMULATION = True  # Memory optimization
```

## ğŸ“ˆ Ä°lerleme Takibi

### Training History

```python
# Training history JSON formatÄ±
{
    "resnet50": {
        "note": "Best pre-trained model",
        "val_acc": 64.67
    },
    "efficientnet_b0": {
        "train_loss": [2.51, 2.35, ...],
        "train_acc": [48.22, 49.67, ...],
        "val_loss": [2.82, 2.29, ...],
        "val_acc": [54.50, 55.94, ...]
    },
    "mobilenet": { ... },
    "meta_learner": { ... },
    "fine_tuning": { ... }
}
```

### GÃ¶rselleÅŸtirme

```bash
# Training curves
python visualize_training.py --history runs/optimal_ensemble/training_history.json

# Confusion matrix
python evaluate_optimal_ensemble.py --confusion-matrix

# Per-class accuracy
python evaluate_optimal_ensemble.py --per-class
```

## ğŸ§ª Test

### Unit Tests

```bash
# TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r
python -m pytest tests/

# Specific test
python test_ensemble.py
```

### Model Validation

```bash
# Model integrity check
python check_model.py

# Quick validation
python quick_evaluate.py

# Full evaluation
python evaluate_optimal_ensemble.py
```

## ğŸ¤ KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! LÃ¼tfen ÅŸu adÄ±mlarÄ± izleyin:

1. Fork edin
2. Feature branch oluÅŸturun (`git checkout -b feature/AmazingFeature`)
3. Commit edin (`git commit -m 'Add some AmazingFeature'`)
4. Push edin (`git push origin feature/AmazingFeature`)
5. Pull Request aÃ§Ä±n

### GeliÅŸtirme OrtamÄ±

```bash
# Development dependencies
pip install -r requirements-dev.txt

# Pre-commit hooks
pre-commit install

# Code formatting
black .
isort .

# Linting
flake8 .
pylint *.py
```

## ğŸ› Sorun Giderme

### CUDA Out of Memory

```python
# Batch size'Ä± dÃ¼ÅŸÃ¼rÃ¼n
BATCH_SIZE = 4

# veya gradient accumulation artÄ±rÄ±n
ACCUMULATION_STEPS = 8
```

### Model YÃ¼kleme HatasÄ±

```bash
# Model dosyasÄ±nÄ± kontrol edin
python check_model.py --model runs/optimal_ensemble/optimal_ensemble_final.pth

# Yeniden indirin
python download_models.py
```

### Docker Build HatasÄ±

```bash
# Cache temizle
docker system prune -a

# Rebuild
docker-compose build --no-cache
```

## ğŸ“ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

## ğŸ‘¨â€ğŸ’» Yazar

**Berke GazioÄŸlu**
- GitHub: [@berkegazioglu](https://github.com/berkegazioglu)

## ğŸ™ TeÅŸekkÃ¼rler

- PyTorch ekibine deep learning framework iÃ§in
- Kaggle'a veri seti iÃ§in
- AÃ§Ä±k kaynak topluluÄŸuna pretrained modeller iÃ§in
- TÃ¼m katkÄ±da bulunanlara

## ğŸ“š Referanslar

1. He, K., et al. (2016). "Deep Residual Learning for Image Recognition"
2. Tan, M., & Le, Q. (2019). "EfficientNet: Rethinking Model Scaling"
3. Howard, A., et al. (2019). "Searching for MobileNetV3"
4. Zhang, H., et al. (2017). "mixup: Beyond Empirical Risk Minimization"

---

â­ Projeyi beÄŸendiyseniz yÄ±ldÄ±z vermeyi unutmayÄ±n!

ğŸ“§ SorularÄ±nÄ±z iÃ§in: [Issue aÃ§Ä±n](https://github.com/berkegazioglu/kedi-cins-tahmini/issues)
